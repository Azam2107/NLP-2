# -*- coding: utf-8 -*-
"""NLP ASSIGNMENT2 AZAM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IknPr85wR3SmMw_HLmfH36YU07TewTfQ
"""

import numpy as np
import pandas as pd
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
import re
from nltk.stem import WordNetLemmatizer
nltk.download('punkt')
nltk.download('wordnet')

imdb=pd.read_csv('IMDB Dataset.csv')
imdb.head()

rev=imdb.iloc[:,0].values
sent=imdb.iloc[:,1].values

print(len(rev))
print(len(sent))

text=[]
for index,review in enumerate(REV):
  text.append((REV,SENT[index]))

print(text[1])

from random import shuffle 
shuffle(text)

from nltk import word_tokenize
words = []
for w in rev:
    words+=word_tokenize(w)

words=[word.lower() for word in words]
words[:10]

from nltk import FreqDist
words_freq = FreqDist(words)
print (words_freq)
print (words_freq.most_common(20))

import string
stopwords_english=stopwords.words("english")
clean_words = []
for word in words:
    if word not in stopwords_english and word not in string.punctuation and word not in ['br',"'s","n't","''",'``','...','..']:
        clean_words.append(word)
print(clean_words[:100])

words_freq = FreqDist(clean_words)
print(words_freq)
print(words_freq.most_common(20))

print (len(words_freq))
 
common_words = words_freq.most_common(1000)

word_features = [item[0] for item in common_words]
print (word_features[:10])

def FEATURES_FIN(document):
    document_words = document
    print(document_words)
   
    features = {}
    for word in word_features:
        features['contains(%s)' % word] = (word in document_words)
    return(features)

movie_review_file=str(REV[5])
print(movie_review_file)
print(FEATURES_FIN(str(movie_review_file)))

feature_set = [(features(doc), category) for (doc, category) in TEXT]

print (len(feature_set)) # Output: 2000
test_set = feature_set[:3000]
train_set = feature_set[3000:]
 
print (len(train_set)) # Output: 1600
print (len(test_set))

from nltk import NaiveBayesClassifier
 classifier = NaiveBayesClassifier.train(train_set)

from nltk import classify 
 
accuracy = classify.accuracy(classifier, test_set)
print (accuracy)